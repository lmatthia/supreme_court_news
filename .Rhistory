isOther = TRUE
)
upset_format_hardball_sets <- create_upset_plot(df_upset_format_hardball_sets, UpsetSegmentFormats, aspect_ratio = 1/1)
df_upset_format_special_report_sets <-
df_channel_split %>%
filter(NewsProgram == "SpecialReport") %>%
prepare_data_for_upset(
UpsetSegmentFormats,
isOther = TRUE
)
upset_format_special_report_sets <- create_upset_plot(df_upset_format_special_report_sets, UpsetSegmentFormats, aspect_ratio = 1/1)
ggarrange(upset_format_special_report_sets, upset_format_hardball_sets)
ggarrange(upset_format_pre2000_network, upset_format_post2000_network, upset_format_post2000_cable)
df_upset_format_pre2000_network <-
df_channel_split %>%
filter(ChannelTypeSplit == "NetworkNewsPre2000") %>%
prepare_data_for_upset(
UpsetSegmentFormats,
isOther = FALSE
)
upset_format_pre2000_network <- create_upset_plot(df_upset_format_pre2000_network, UpsetSegmentFormats, aspect_ratio = 1/1)
ggarrange(upset_format_pre2000_network, upset_format_post2000_network, upset_format_post2000_cable)
df_upset_format_post2000_network <-
df_channel_split %>%
filter(ChannelTypeSplit == "NetworkNewsPost2000") %>%
prepare_data_for_upset(
UpsetSegmentFormats,
isOther = FALSE
)
upset_format_post2000_network <- create_upset_plot(df_upset_format_post2000_network, UpsetSegmentFormats, aspect_ratio = 1/1)
df_upset_format_post2000_cable_sets <-
df_channel_split %>%
filter(ChannelTypeSplit == "CableNews") %>%
prepare_data_for_upset(
UpsetSegmentFormats,
isOther = TRUE
)
upset_format_post2000_cable_sets <- create_upset_plot(df_upset_format_post2000_cable_sets, UpsetSegmentFormats, aspect_ratio = 1/1)
ggarrange(upset_format_pre2000_network, upset_format_post2000_network, upset_format_post2000_cable_sets)
ggarrange(upset_format_pre2000_network, upset_format_post2000_network, upset_format_post2000_cable_sets, ncol = 1)
ggarrange(upset_format_pre2000_network, upset_format_post2000_network, upset_format_post2000_cable_sets, nrow = 1)
upset_format_channel
# Pre-2000 Network News
df_upset_format_pre2000_network <-
df_channel_split %>%
filter(ChannelTypeSplit == "NetworkNewsPre2000") %>%
prepare_data_for_upset(
UpsetSegmentFormats,
isOther = FALSE
)
upset_format_pre2000_network <- create_upset_plot(df_upset_format_pre2000_network, UpsetSegmentFormats, aspect_ratio = 1/1)
#ggsave(path = "plots/NewsFormat", filename = "upset_format_pre2000_network.svg", width = 6.3, height = 4.72)
# Post-2000 Network News
df_upset_format_post2000_network <-
df_channel_split %>%
filter(ChannelTypeSplit == "NetworkNewsPost2000") %>%
prepare_data_for_upset(
UpsetSegmentFormats,
isOther = FALSE
)
upset_format_post2000_network <- create_upset_plot(df_upset_format_post2000_network, UpsetSegmentFormats, aspect_ratio = 1/1)
#ggsave(path = "plots/NewsFormat", filename = "upset_format_post2000_network.svg", width = 6.3, height = 4.72)
# Cable News
## Without sets
df_upset_format_post2000_cable <-
df_channel_split %>%
filter(ChannelTypeSplit == "CableNews") %>%
prepare_data_for_upset(
UpsetSegmentFormats,
isOther = FALSE
)
upset_format_post2000_cable <- create_upset_plot(df_upset_format_post2000_cable, UpsetSegmentFormats, aspect_ratio = 1/1)
#ggsave(path = "plots/NewsFormat", filename = "upset_format_post2000_cable.svg", width = 6.3, height = 4.72)
## With sets
df_upset_format_post2000_cable_sets <-
df_channel_split %>%
filter(ChannelTypeSplit == "CableNews") %>%
prepare_data_for_upset(
UpsetSegmentFormats,
isOther = TRUE
)
upset_format_post2000_cable_sets <- create_upset_plot(df_upset_format_post2000_cable_sets, UpsetSegmentFormats, aspect_ratio = 1/1)
upset_format_channel <- ggarrange(upset_format_pre2000_network, upset_format_post2000_network, upset_format_post2000_cable_sets, nrow = 1)
upset_format_channel
create_upset_plot(df_upset_format_post2000_network, UpsetSegmentFormats, aspect_ratio = 2/1)
knitr::include_graphics("AdobeEdits/bar_prop_mntns_emo_cable_edit.png")
# Plot by Cable News Program
bar_emo_present_cable <- mntn_emo_robust %>% filter(ChannelTypeSplit == "CableNews") %>%
create_bar_emo_present(., "NewsProgram")  +
labs(subtitle = "Share of news mentions that included emotional appeals,\nby cable news program (excluding identical mentions)")
bar_emo_present_cable
ggsave(path = "plots/NewsPresentation", filename = "bar_emo_present_cable.svg", width = 6.3, height = 4.72)
create_bar_emo_present <- function(data, group_var) {
# Group data and calculate percentages
df_grouped <- data %>%
group_by(!!sym(group_var), EmotionPresent) %>%
summarise(count = n()) %>%
mutate(perc = count/sum(count)) %>%
ungroup()
# Define theme
theme_emo_horizontal <- theme_void(base_size = 14) %+replace%
theme(axis.text.y = element_text(color = "black"))
# Create plot
plot <- ggplot(df_grouped, aes(x = fct_rev(factor(!!sym(group_var))), y = perc, fill = factor(EmotionPresent))) +
geom_bar(stat="identity", width = 0.7) +
geom_text(data = subset(df_grouped, EmotionPresent == 1),
aes(label = scales::percent(perc)),
position = position_stack(vjust = 0.5),
color = "white") +
scale_y_continuous(labels = scales::percent_format()) +
labs(x = group_var, y = NULL, fill = "EmotionPresent") +
theme_emo_horizontal +
coord_flip()
return(plot)
}
# Plot by Channel Type
bar_emo_present_channel <- create_bar_emo_present(mntn_emo_robust, "ChannelTypeSplit") +
labs(subtitle = "Share of news mentions that included emotional appeals,\nby channel type and time period (excluding identical mentions)")
bar_emo_present_channel
##Save plot
ggsave(path = "plots/NewsPresentation", filename = "bar_emo_present_channel.svg", width = 6.3, height = 4.72)
# Plot by Cable News Program
bar_emo_present_cable <- mntn_emo_robust %>% filter(ChannelTypeSplit == "CableNews") %>%
create_bar_emo_present(., "NewsProgram")  +
labs(subtitle = "Share of news mentions that included emotional appeals,\nby cable news program (excluding identical mentions)")
bar_emo_present_cable
ggsave(path = "plots/NewsPresentation", filename = "bar_emo_present_cable.svg", width = 6.3, height = 4.72)
# Read the "Emo" sheet from the local copy. Call this "mntn_emo"
mntn_emo <- read.csv("raw_data/NewsEmotion.csv")
View(mntn_emo)
View(mntn_emo)
# Set factor levels and labels
TimePeriodLevels <- c("2000_2018", "1990_1999")
# Mutate columns in mntn_emo
mntn_emo$ChannelType <- factor(mntn_emo$ChannelType,
levels = c("NetworkNews", "CableNews")
)
mntn_emo$IssueArea <- factor(mntn_emo$IssueArea,
levels = c("Abortion", "EconomicActivity", "FirstAmendment","Sex Discrimination"))
mntn_emo$NewsProgram <- factor(mntn_emo$NewsProgram, levels = c("Hardball", "SpecialReport", "WorldNewsTonight"))
mntn_emo$TimePeriod <- factor(mntn_emo$TimePeriod,
levels = TimePeriodLevels
)
mntn_emo$MultiMentionType <- as.factor(mntn_emo$MultiMentionType)
mntn_emo$AnchorOnly <- as.numeric(as.character(mntn_emo$AnchorOnly))
mntn_emo$Correspondent <- as.numeric(as.character(mntn_emo$Correspondent))
mntn_emo$Debate<- as.numeric(as.character(mntn_emo$Debate))
mntn_emo$NewsInterview <- as.numeric(as.character(mntn_emo$NewsInterview))
mntn_emo <- mntn_emo %>%
mutate(ChannelTypeSplit = case_when(ChannelType == "CableNews" &  TimePeriod == "2000_2018" ~ "CableNews", ChannelType == "NetworkNews" &  TimePeriod == "2000_2018" ~ "NetworkNewsPost2000", ChannelType == "NetworkNews" &  TimePeriod == "1990_1999" ~ "NetworkNewsPre2000"))
mntn_emo$ChannelTypeSplit <- factor(mntn_emo$ChannelTypeSplit, levels = c("NetworkNewsPre2000", "NetworkNewsPost2000", "CableNews"))
#Robustness set with Identical news mentions included only once
# Create a new dataframe that only includes entries with "MultiMentionMentionType" == "Identical"
mntn_emo_Identical <- mntn_emo[mntn_emo$MultiMentionType == "Identical",]
# Use the unique function to only keep the first instance of each "TranscriptID" for Identicals
mntn_emo_Identical <- mntn_emo_Identical[!duplicated(mntn_emo_Identical$TranscriptID),]
# Create a new dataframe that only includes entries with "MultiMentionMentionType" != "Identical"
mntn_emo_non_Identical <- mntn_emo[mntn_emo$MultiMentionType != "Identical",]
# Concatenate the filtered dataframes
mntn_emo_robust <- rbind(mntn_emo_non_Identical, mntn_emo_Identical)
# Get spreadsheet from Google Drive and save a local copy
googledrive::drive_download(
googledrive::as_id("https://docs.google.com/spreadsheets/d/1Ov8w4d9WbTSIl3FNasehwQhoZzZ-SD74L6-CH2uVlgA/edit#gid=1740013535"),
path = "raw_data/SupremeCourtNews.xlsx",
overwrite = TRUE
)
# Read the "Emo" sheet from the local copy. Call this "mntn_emo"
mntn_emo <- readxl::read_xlsx("raw_data/SupremeCourtNews.xlsx",
sheet =
"NewsEmotion"
)
# Set factor levels and labels
TimePeriodLevels <- c("2000_2018", "1990_1999")
# Mutate columns in mntn_emo
mntn_emo$ChannelType <- factor(mntn_emo$ChannelType,
levels = c("NetworkNews", "CableNews")
)
mntn_emo$IssueArea <- factor(mntn_emo$IssueArea,
levels = c("Abortion", "EconomicActivity", "FirstAmendment","Sex Discrimination"))
mntn_emo$NewsProgram <- factor(mntn_emo$NewsProgram, levels = c("Hardball", "SpecialReport", "WorldNewsTonight"))
mntn_emo$TimePeriod <- factor(mntn_emo$TimePeriod,
levels = TimePeriodLevels
)
mntn_emo$MultiMentionType <- as.factor(mntn_emo$MultiMentionType)
mntn_emo <- mntn_emo %>%
mutate(ChannelTypeSplit = case_when(ChannelType == "CableNews" &  TimePeriod == "2000_2018" ~ "CableNews", ChannelType == "NetworkNews" &  TimePeriod == "2000_2018" ~ "NetworkNewsPost2000", ChannelType == "NetworkNews" &  TimePeriod == "1990_1999" ~ "NetworkNewsPre2000"))
mntn_emo$ChannelTypeSplit <- factor(mntn_emo$ChannelTypeSplit, levels = c("NetworkNewsPre2000", "NetworkNewsPost2000", "CableNews"))
#Robustness set with Identical news mentions included only once
# Create a new dataframe that only includes entries with "MultiMentionMentionType" == "Identical"
mntn_emo_Identical <- mntn_emo[mntn_emo$MultiMentionType == "Identical",]
# Use the unique function to only keep the first instance of each "TranscriptID" for Identicals
mntn_emo_Identical <- mntn_emo_Identical[!duplicated(mntn_emo_Identical$TranscriptID),]
# Create a new dataframe that only includes entries with "MultiMentionMentionType" != "Identical"
mntn_emo_non_Identical <- mntn_emo[mntn_emo$MultiMentionType != "Identical",]
# Concatenate the filtered dataframes
mntn_emo_robust <- rbind(mntn_emo_non_Identical, mntn_emo_Identical)
googledrive::drive_download(
googledrive::as_id("https://docs.google.com/spreadsheets/d/1Ov8w4d9WbTSIl3FNasehwQhoZzZ-SD74L6-CH2uVlgA/edit#gid=1740013535"),
path = "raw_data/SupremeCourtNews.xlsx",
overwrite = TRUE
)
# Read the "NewsMentionsSample" sheet from the local copy. Call this "mntn_raw"
mntn_raw <- readxl::read_xlsx("raw_data/SupremeCourtNews.xlsx",
sheet =
"NewsMentionSample"
)
# Read the "SupremeCourtCases" sheet from the local copy. Call this "cases_raw"
cases_raw <- readxl::read_xlsx("raw_data/SupremeCourtNews.xlsx",
sheet =
"SupremeCourtCaseIndex"
)
# Read the "NewsMentionSample" sheet from the local copy. Call this "mntn_raw"
mntn_raw <- read.csv("data/NewsMentionSample.csv")
mntn_emo <- read.csv("data/NewsEmotion.csv")
# Read the local copy. Call this "mntn_raw"
mntn_raw <- read.csv("data/NewsTranscriptIndex.csv")
# Read the "NewsMentionsSample" sheet from the local copy. Call this "mntn_raw"
mntn_raw <- read.csv("data/NewsMentionSample.csv")
# Read the local copy. Call this "mntn_emo"
mntn_emo <- read_csv("data/NewsEmotion.csv")
# Read the local copy. Call this "mntn_emo"
mntn_emo <- read.csv("data/NewsEmotion.csv")
# Read the local copy. Call this "mntn_raw"
mntn_raw <- read.csv("data/NewsMentionSample.csv")
# Read the local copy. Call this "cases_raw"
cases_raw <- read.csv("data/SupremeCourtCaseIndex.csv")
# Read the local copy. Call this "mntn_raw"
mntn_raw <- read.csv("data/NewsMentionSample.csv")
# Read the local copy. Call this "cases_raw"
cases_raw <- read.csv("data/SupremeCourtCaseIndex.csv")
x <- rmarkdown::render("NewsVolumeStatsKopie.RMD", run_pandoc = FALSE, clean = FALSE)
knit_meta <- attr(x, "knit_meta")
rmarkdown::render(input = 'NewsVolumeStatsKopie.knit.md'    , knit_meta = knit_meta )
x <- rmarkdown::render("data/NewsVolumeStatsKopie.RMD", run_pandoc = FALSE, clean = FALSE)
knit_meta <- attr(x, "knit_meta")
rmarkdown::render(input = 'data/NewsVolumeStatsKopie.knit.md'    , knit_meta = knit_meta )
x <- rmarkdown::render("rmd/NewsVolumeStatsKopie.RMD", run_pandoc = FALSE, clean = FALSE)
knit_meta <- attr(x, "knit_meta")
rmarkdown::render(input = 'rmd/NewsVolumeStatsKopie.knit.md'    , knit_meta = knit_meta )
x <- rmarkdown::render("rmd/NewsVolumeStatsKopie.rmd", run_pandoc = FALSE, clean = FALSE)
file.exists("data/NewsMentionSample.csv")
x <- rmarkdown::render("rmd/NewsVolumeStats.rmd", run_pandoc = FALSE, clean = FALSE)
knit_meta <- attr(x, "knit_meta")
rmarkdown::render(input = 'rmd/NewsVolumeStats.knit.md'    , knit_meta = knit_meta )
library(datawizard)
#library(ggstatsplot)
library(gt)
library(janitor)
library(tidyverse)
# Read the "NewsMentionsSample" sheet from the local copy. Call this "mntn_raw"
mntn_raw <- read.csv("data/NewsMentionSample.csv")
# Set factor levels and labels
IssueAreaLevels <- c(
"Abortion", "EconomicActivity",
"FirstAmendment",
"SexDiscrimination"
)
CaseStageLevels <- c(
"Cert", "PostCert", "Argument",
"PostArgument", "Decision",
"PostDecision"
)
ChannelTypeLevels <- c("NetworkNews", "CableNews")
TimePeriodLevels <- c("2000_2018", "1990_1999")
# Mutate columns in mntn_raw
mntn_raw$IssueArea <- factor(mntn_raw$IssueArea,
levels = IssueAreaLevels
)
mntn_raw$CaseStage <- factor(mntn_raw$CaseStage,
levels = CaseStageLevels
)
mntn_raw$ChannelType <- factor(mntn_raw$ChannelType,
levels = c("NetworkNews", "CableNews")
)
mntn_raw$NewsProgram <- factor(mntn_raw$NewsProgram, levels = c("Hardball", "SpecialReport", "WorldNewsTonight"))
mntn_raw$TimePeriod <- factor(mntn_raw$TimePeriod,
levels = TimePeriodLevels
)
mntn_raw$CaseStageCondensed <- fct_collapse(mntn_raw$CaseStage,
"PreDecision" = c(
"Cert", "PostCert",
"Argument", "PostArgument"),
"Decision" = "Decision",
"PostDecision" = "PostDecision"
)
mntn_raw$CaseStageCondensed <- factor(mntn_raw$CaseStageCondensed, levels = c("PreDecision", "Decision", "PostDecision"))
mntn_raw$MentionContext <- factor(mntn_raw$MentionContext,
levels = c("1", "2", "3"))
mntn_raw$AnchorOnly <- as.numeric(as.character(mntn_raw$AnchorOnly))
mntn_raw$Correspondent <- as.numeric(as.character(mntn_raw$Correspondent))
mntn_raw$Debate <- as.numeric(as.character(mntn_raw$Debate))
mntn_raw$NewsInterview <- as.numeric(as.character(mntn_raw$NewsInterview))
#Create new column with collapsed channel types
df_channel_split <- mntn_raw %>%
mutate(ChannelTypeSplit = case_when(ChannelType == "CableNews" &  TimePeriod == "2000_2018" ~ "CableNews", ChannelType == "NetworkNews" &  TimePeriod == "2000_2018" ~ "NetworkNewsPost2000", ChannelType == "NetworkNews" &  TimePeriod == "1990_1999" ~ "NetworkNewsPre2000"))
#Convert new column to factor
ChannelTypeSplitLevels <- c("NetworkNewsPre2000","NetworkNewsPost2000","CableNews")
df_channel_split$ChannelTypeSplit <- factor(df_channel_split$ChannelTypeSplit, levels = ChannelTypeSplitLevels, labels = ChannelTypeSplitLevels)
#Robustness set with identical news mentions included only once
# Create a new dataframe that only includes entries with "MultiMentionMentionType" == "identical"
df_channel_split_identical <- df_channel_split[df_channel_split$MultiMentionType == "Identical",]
# Use the unique function to only keep the first instance of each "TranscriptID" for identicals
df_channel_split_identical <- df_channel_split_identical[!duplicated(df_channel_split_identical$TranscriptID),]
# Create a new dataframe that only includes entries with "MultiMentionMentionType" != "identical"
df_channel_split_non_identical <- df_channel_split[df_channel_split$MultiMentionType != "Identical",]
# Concatenate the filtered dataframes
df_channel_split_robust <- rbind(df_channel_split_non_identical, df_channel_split_identical)
#Function for chisq pre-2000 & post-2000 network news ~ segment formats
function_chisq_SegmentFormat_time <- function(df, news_var, SegmentFormat){
news_var <- sym(news_var)
SegmentFormat <- sym(SegmentFormat)
x <- df %>%
filter(ChannelTypeSplit != "CableNews") %>%
mutate_if(is.numeric,as.factor) %>%
tabyl(!!news_var , !! SegmentFormat, show_missing_levels = FALSE) %>%
chisq.test(correct = FALSE)
return(x)
}
function_chisq_SegmentFormat_channel <- function(df, news_var, SegmentFormat){
news_var <- sym(news_var)
SegmentFormat <- sym(SegmentFormat)
x <- df %>%
filter(ChannelTypeSplit != "NetworkNewsPre2000") %>%
mutate_if(is.numeric,as.factor) %>%
tabyl(!!news_var, !!SegmentFormat, show_missing_levels = FALSE) %>%
chisq.test(correct = FALSE)
return(x)
}
#Function for chisq cable programs ~ segment formats
function_chisq_SegmentFormat_cable <- function(df, news_var, SegmentFormat){
news_var <- sym(news_var)
SegmentFormat <- sym(SegmentFormat)
x <- df %>%
filter(ChannelTypeSplit == "CableNews") %>%
mutate_if(is.numeric,as.factor) %>%
tabyl(!!news_var, !!SegmentFormat, show_missing_levels = FALSE) %>%
chisq.test(correct = FALSE)
return(x)
}
#Function to print chisq results, observed values, expected values, and standardized residuals
consolidate_chisq_results <- function(chisq_context_time, context_col) {
observed <- chisq_context_time$observed
expected <- chisq_context_time$expected
stdres <- chisq_context_time$stdres
# Dynamically get the name of the first column
first_col_name <- colnames(observed)[1]
if (context_col == "Present") {
result_df <- data.frame(
FirstColumn = observed[, 1],
Observed_1 = observed[, 2],
Observed_2 = observed[, 3],
Expected_1 = expected[, 2],
Expected_2 = expected[, 3],
StdRes_1 = stdres[, 2],
StdRes_2 = stdres[, 3]
)
} else {
result_df <- data.frame(
FirstColumn = observed[, 1],
Observed_1 = observed[, 2],
Observed_2 = observed[, 3],
Observed_3 = observed[, 4],
Expected_1 = expected[, 2],
Expected_2 = expected[, 3],
Expected_3 = expected[, 4],
StdRes_1 = stdres[, 2],
StdRes_2 = stdres[, 3],
StdRes_3 = stdres[, 4]
)
}
long_df <- result_df %>%
pivot_longer(
cols = starts_with("Observed") | starts_with("Expected") | starts_with("StdRes"),
names_to = c(".value", context_col),
names_pattern = "(Observed|Expected|StdRes)_(\\d+)"
) %>%
select(FirstColumn, all_of(context_col), Observed, Expected, StdRes) %>%
rename_at(vars(FirstColumn), ~first_col_name)  # Rename 'FirstColumn' back to its original name
long_df <- long_df %>%
mutate(
!!context_col := case_when(
context_col == "Present" ~ factor(!!sym(context_col), levels = c("1", "2"), labels = c("No", "Yes")),
context_col == "MentionContext" ~ factor(!!sym(context_col), levels = c("1", "2", "3"), labels = c("Same", "Related", "Different")),
context_col == "MntnLengthGroup" ~ factor(!!sym(context_col), levels = c("1", "2", "3"), labels = c("Short", "Medium", "Long")),
TRUE ~ as.factor(!!sym(context_col))
),
Expected = round(Expected, digits = 2),
StdRes = round(StdRes, digits = 2)
)
return(long_df)
}
##News Interview Segments
chisq_interview_time_robust <- function_chisq_SegmentFormat_time(df_channel_split_robust, news_var = "ChannelTypeSplit", SegmentFormat = "NewsInterview")
chisq_interview_time_robust
##Correspondent Segments
chisq_correspondent_time_robust <- function_chisq_SegmentFormat_time(df_channel_split_robust, news_var = "ChannelTypeSplit", SegmentFormat = "Correspondent")
chisq_correspondent_time_robust
##News Interview Segments
chisq_interview_time <- function_chisq_SegmentFormat_time(df_channel_split, news_var = "ChannelTypeSplit", SegmentFormat = "NewsInterview")
chisq_interview_time
##News Interview Segments
chisq_interview_time_robust <- function_chisq_SegmentFormat_time(df_channel_split_robust, news_var = "ChannelTypeSplit", SegmentFormat = "NewsInterview")
chisq_interview_time_robust
##News Interview Segments
chisq_interview_time_robust <- function_chisq_SegmentFormat_time(df_channel_split_robust, news_var = "ChannelTypeSplit", SegmentFormat = "NewsInterview")
chisq_interview_time_robust
mntn_length <- df_channel_split %>%
mutate(MntnLengthSeconds = WordCountRAND / 2.25) %>%
mutate(MntnLengthSeconds = round(MntnLengthSeconds, digits = 0)) %>%
mutate(MntnLengthGroup = case_when(MntnLengthSeconds >= 120 ~ "Long",
MntnLengthSeconds >= 30 ~ "Medium",
MntnLengthSeconds < 30 ~ "Short")) %>%
mutate(MntnLengthGroup = factor(.$MntnLengthGroup,
levels = c("Short", "Medium", "Long")))
#How long were Supreme Court case mentions on cable programs?
##Convert word count to seconds based on 135 words per 60 seconds/2.25 words per second (Edwards III & Howell, 2011, p. 258). Categorize mention length: short (shorter than 30 seconds), medium (31 seconds to 120 seconds), or long (longer than 120 seconds)
mntn_length <- df_channel_split %>%
mutate(MntnLengthSeconds = WordCountRAND/2.25) %>%
mutate(MntnLengthSeconds = round(MntnLengthSeconds, digits = 0)) %>%
mutate(MntnLengthGroup = case_when(MntnLengthSeconds >= 120 ~ "Long",
MntnLengthSeconds >= 30 ~ "Medium",
MntnLengthSeconds < 30 ~ "Short")) %>%
mutate(MntnLengthGroup = factor(.$MntnLengthGroup,
levels = c("Short", "Medium", "Long")))
##Contingency table ChannelTypeSplit ~ Mention Length
contingency_mntn_length_channel_time <-  mntn_length %>%
tabyl(ChannelTypeSplit, MntnLengthGroup)
chisq_mntn_length_time <- contingency_mntn_length_channel_time %>%
filter(ChannelTypeSplit != "CableNews") %>%
chisq.test(correct = FALSE)
chisq_mntn_length_time
df_channel_split
#How long were Supreme Court case mentions on cable programs?
##Convert word count to seconds based on 135 words per 60 seconds/2.25 words per second (Edwards III & Howell, 2011, p. 258). Categorize mention length: short (shorter than 30 seconds), medium (31 seconds to 120 seconds), or long (longer than 120 seconds)
mntn_length <- df_channel_split %>%
mutate(MntnLengthSeconds = (WordCountRAND/2.25)) %>%
mutate(MntnLengthSeconds = round(MntnLengthSeconds, digits = 0)) %>%
mutate(MntnLengthGroup = case_when(MntnLengthSeconds >= 120 ~ "Long",
MntnLengthSeconds >= 30 ~ "Medium",
MntnLengthSeconds < 30 ~ "Short")) %>%
mutate(MntnLengthGroup = factor(.$MntnLengthGroup,
levels = c("Short", "Medium", "Long")))
##Contingency table ChannelTypeSplit ~ Mention Length
contingency_mntn_length_channel_time <-  mntn_length %>%
tabyl(ChannelTypeSplit, MntnLengthGroup)
chisq_mntn_length_time <- contingency_mntn_length_channel_time %>%
filter(ChannelTypeSplit != "CableNews") %>%
chisq.test(correct = FALSE)
chisq_mntn_length_time
View(df_channel_split)
View(df_channel_split)
#How long were Supreme Court case mentions on cable programs?
##Convert word count to seconds based on 135 words per 60 seconds/2.25 words per second (Edwards III & Howell, 2011, p. 258). Categorize mention length: short (shorter than 30 seconds), medium (31 seconds to 120 seconds), or long (longer than 120 seconds)
mntn_length <- df_channel_split %>%
mutate(MntnLengthSeconds = as.numeric(WordCountRAND)/2.25) %>%
mutate(MntnLengthSeconds = round(MntnLengthSeconds, digits = 0)) %>%
mutate(MntnLengthGroup = case_when(MntnLengthSeconds >= 120 ~ "Long",
MntnLengthSeconds >= 30 ~ "Medium",
MntnLengthSeconds < 30 ~ "Short")) %>%
mutate(MntnLengthGroup = factor(.$MntnLengthGroup,
levels = c("Short", "Medium", "Long")))
##Contingency table ChannelTypeSplit ~ Mention Length
contingency_mntn_length_channel_time <-  mntn_length %>%
tabyl(ChannelTypeSplit, MntnLengthGroup)
chisq_mntn_length_time <- contingency_mntn_length_channel_time %>%
filter(ChannelTypeSplit != "CableNews") %>%
chisq.test(correct = FALSE)
chisq_mntn_length_time
#How long were Supreme Court case mentions on cable programs?
##Convert word count to seconds based on 135 words per 60 seconds/2.25 words per second (Edwards III & Howell, 2011, p. 258). Categorize mention length: short (shorter than 30 seconds), medium (31 seconds to 120 seconds), or long (longer than 120 seconds)
mntn_length <- df_channel_split %>%
mutate(MntnLengthSeconds = numeric(WordCountRAND)/2.25) %>%
mutate(MntnLengthSeconds = round(MntnLengthSeconds, digits = 0)) %>%
mutate(MntnLengthGroup = case_when(MntnLengthSeconds >= 120 ~ "Long",
MntnLengthSeconds >= 30 ~ "Medium",
MntnLengthSeconds < 30 ~ "Short")) %>%
mutate(MntnLengthGroup = factor(.$MntnLengthGroup,
levels = c("Short", "Medium", "Long")))
##Contingency table ChannelTypeSplit ~ Mention Length
contingency_mntn_length_channel_time <-  mntn_length %>%
tabyl(ChannelTypeSplit, MntnLengthGroup)
chisq_mntn_length_time <- contingency_mntn_length_channel_time %>%
filter(ChannelTypeSplit != "CableNews") %>%
chisq.test(correct = FALSE)
chisq_mntn_length_time
#How long were Supreme Court case mentions on cable programs?
##Convert word count to seconds based on 135 words per 60 seconds/2.25 words per second (Edwards III & Howell, 2011, p. 258). Categorize mention length: short (shorter than 30 seconds), medium (31 seconds to 120 seconds), or long (longer than 120 seconds)
df_channel_split$WordCountRAND <- numeric(df_channel_split$WordCountRAND)
#How long were Supreme Court case mentions on cable programs?
##Convert word count to seconds based on 135 words per 60 seconds/2.25 words per second (Edwards III & Howell, 2011, p. 258). Categorize mention length: short (shorter than 30 seconds), medium (31 seconds to 120 seconds), or long (longer than 120 seconds)
df_channel_split$WordCountRAND <- as.numeric(df_channel_split$WordCountRAND)
#How long were Supreme Court case mentions on cable programs?
##Convert word count to seconds based on 135 words per 60 seconds/2.25 words per second (Edwards III & Howell, 2011, p. 258). Categorize mention length: short (shorter than 30 seconds), medium (31 seconds to 120 seconds), or long (longer than 120 seconds)
df_channel_split$WordCountRAND <- as.numeric(df_channel_split$WordCountRAND)
#How long were Supreme Court case mentions on cable programs?
##Convert word count to seconds based on 135 words per 60 seconds/2.25 words per second (Edwards III & Howell, 2011, p. 258). Categorize mention length: short (shorter than 30 seconds), medium (31 seconds to 120 seconds), or long (longer than 120 seconds)
df_channel_split$WordCountRAND <- as.numeric(df_channel_split$WordCountRAND)
mntn_length <- df_channel_split %>%
mutate(MntnLengthSeconds = WordCountRAND/2.25) %>%
mutate(MntnLengthSeconds = round(MntnLengthSeconds, digits = 0)) %>%
mutate(MntnLengthGroup = case_when(MntnLengthSeconds >= 120 ~ "Long",
MntnLengthSeconds >= 30 ~ "Medium",
MntnLengthSeconds < 30 ~ "Short")) %>%
mutate(MntnLengthGroup = factor(.$MntnLengthGroup,
levels = c("Short", "Medium", "Long")))
##Contingency table ChannelTypeSplit ~ Mention Length
contingency_mntn_length_channel_time <-  mntn_length %>%
tabyl(ChannelTypeSplit, MntnLengthGroup)
chisq_mntn_length_time <- contingency_mntn_length_channel_time %>%
filter(ChannelTypeSplit != "CableNews") %>%
chisq.test(correct = FALSE)
chisq_mntn_length_time
